{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65476cfd",
   "metadata": {},
   "source": [
    "# Thunder Acoustics in the Wild - Quick Start\n",
    "\n",
    "This notebook demonstrates the complete pipeline for thunder acoustic analysis:\n",
    "\n",
    "1. **Setup**: Import libraries and load configuration\n",
    "2. **Audio Extraction**: Extract audio from video (or load existing)\n",
    "3. **Preprocessing**: Bandpass filter, noise reduction, normalization\n",
    "4. **Event Detection**: Detect thunder events using energy + spectral analysis\n",
    "5. **Feature Extraction**: Time, frequency, and time-frequency features\n",
    "6. **Visualization**: Waveform, spectrogram, feature distributions\n",
    "7. **Export**: Save results to CSV and JSON\n",
    "\n",
    "**Requirements**: Ensure `thunder` package is installed:\n",
    "```bash\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68501e2c",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Libraries and Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import thunder package\n",
    "from thunder import io, preprocess, detection, features, utils, metadata\n",
    "\n",
    "# Setup logging\n",
    "utils.setup_logging(log_level='INFO')\n",
    "\n",
    "# Load configuration\n",
    "config_path = Path('../configs/default.yaml')\n",
    "config = utils.load_config(config_path)\n",
    "\n",
    "print(\"✓ Libraries imported\")\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  - Sample rate: {config['preprocessing']['sample_rate']} Hz\")\n",
    "print(f\"  - Energy threshold: {config['detection']['energy_threshold']}\")\n",
    "print(f\"  - Spectral threshold: {config['detection']['spectral_threshold']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86002bb8",
   "metadata": {},
   "source": [
    "## 2. Create Output Directory\n",
    "\n",
    "Create a timestamped output directory for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_base = Path('../outputs')\n",
    "output_dir = utils.ensure_output_dir(output_base / 'quickstart_demo', date_prefix=True)\n",
    "\n",
    "print(f\"✓ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036a4c7",
   "metadata": {},
   "source": [
    "## 3. Generate Synthetic Thunder Audio (Demo)\n",
    "\n",
    "For this quickstart, we'll generate synthetic thunder-like audio. In production, you would use `scripts/extract_audio.py` to extract audio from videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfe766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_thunder(duration=10.0, sr=48000):\n",
    "    \"\"\"Generate synthetic thunder-like audio.\"\"\"\n",
    "    t = np.linspace(0, duration, int(sr * duration))\n",
    "    audio = np.zeros_like(t)\n",
    "    \n",
    "    # Add 3 thunder events\n",
    "    events = [\n",
    "        (1.0, 2.5, 0.3),   # (start, end, amplitude)\n",
    "        (4.0, 5.0, 0.5),\n",
    "        (7.5, 9.0, 0.2),\n",
    "    ]\n",
    "    \n",
    "    for start, end, amp in events:\n",
    "        mask = (t >= start) & (t < end)\n",
    "        # Low-frequency rumble (50-200 Hz) + decay envelope\n",
    "        freq = np.random.uniform(50, 200)\n",
    "        envelope = np.exp(-3 * (t[mask] - start) / (end - start))\n",
    "        rumble = amp * envelope * np.sin(2 * np.pi * freq * (t[mask] - start))\n",
    "        \n",
    "        # Add high-frequency crack at start\n",
    "        crack_duration = 0.1\n",
    "        crack_mask = (t >= start) & (t < start + crack_duration)\n",
    "        if crack_mask.sum() > 0:\n",
    "            crack_freq = np.random.uniform(1000, 3000)\n",
    "            crack_env = np.exp(-20 * (t[crack_mask] - start))\n",
    "            crack = amp * 1.5 * crack_env * np.sin(2 * np.pi * crack_freq * (t[crack_mask] - start))\n",
    "            audio[crack_mask] += crack\n",
    "        \n",
    "        audio[mask] += rumble\n",
    "    \n",
    "    # Add noise\n",
    "    noise = 0.01 * np.random.randn(len(audio))\n",
    "    audio += noise\n",
    "    \n",
    "    # Normalize\n",
    "    audio = audio / np.max(np.abs(audio)) * 0.8\n",
    "    \n",
    "    return audio.astype(np.float32), sr\n",
    "\n",
    "# Generate audio\n",
    "audio, sr = generate_synthetic_thunder(duration=10.0, sr=48000)\n",
    "\n",
    "print(f\"✓ Synthetic audio generated\")\n",
    "print(f\"  - Duration: {len(audio) / sr:.2f} seconds\")\n",
    "print(f\"  - Sample rate: {sr} Hz\")\n",
    "print(f\"  - Shape: {audio.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64e1f9",
   "metadata": {},
   "source": [
    "## 4. Preprocessing: Bandpass Filter, Noise Reduction, Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8455e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline\n",
    "preprocess_config = config['preprocessing']\n",
    "audio_processed = preprocess.preprocess_pipeline(audio, sr, preprocess_config)\n",
    "\n",
    "print(\"✓ Preprocessing complete\")\n",
    "print(f\"  - Bandpass filter: {preprocess_config['bandpass']['low_cutoff']}-{preprocess_config['bandpass']['high_cutoff']} Hz\")\n",
    "print(f\"  - Normalization: {preprocess_config['normalize']['method']} @ {preprocess_config['normalize']['target_db']} dB\")\n",
    "print(f\"  - Processed shape: {audio_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e71586",
   "metadata": {},
   "source": [
    "## 5. Event Detection: Combined Energy + Spectral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92947e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect thunder events\n",
    "detection_config = config['detection']\n",
    "events = detection.detect_thunder_events(audio_processed, sr, detection_config)\n",
    "\n",
    "print(f\"✓ Detected {len(events)} events\")\n",
    "for i, event in enumerate(events):\n",
    "    print(f\"  Event {i+1}: {event['start']:.2f}s - {event['end']:.2f}s (duration: {event['duration']:.2f}s, peak: {event['peak_amplitude']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552349e",
   "metadata": {},
   "source": [
    "## 6. Feature Extraction: Time, Frequency, and Time-Frequency Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for all events\n",
    "features_config = config['features']\n",
    "feature_list = features.extract_all_features(audio_processed, sr, events, features_config)\n",
    "\n",
    "# Convert to DataFrame\n",
    "features_df = pd.DataFrame(feature_list)\n",
    "\n",
    "print(f\"✓ Extracted features for {len(feature_list)} events\")\n",
    "print(f\"  - Feature count: {len(features_df.columns)} columns\")\n",
    "print(\"\\nFeature columns:\")\n",
    "print(features_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc3772",
   "metadata": {},
   "source": [
    "### Feature Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display numeric feature summary\n",
    "numeric_cols = features_df.select_dtypes(include=['number']).columns\n",
    "exclude_cols = ['event_id', 'start', 'end', 'duration']\n",
    "feature_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "\n",
    "summary = features_df[feature_cols].describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b31cb4",
   "metadata": {},
   "source": [
    "## 7. Visualization: Waveform with Detected Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "# Time axis\n",
    "time = np.arange(len(audio_processed)) / sr\n",
    "\n",
    "# Plot waveform\n",
    "ax.plot(time, audio_processed, color='steelblue', linewidth=0.7, label='Waveform')\n",
    "\n",
    "# Highlight detected events\n",
    "for i, event in enumerate(events):\n",
    "    ax.axvspan(event['start'], event['end'], alpha=0.3, color='red', \n",
    "               label='Thunder Event' if i == 0 else '')\n",
    "    # Mark peak\n",
    "    ax.axvline(event['peak_time'], color='darkred', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Amplitude', fontsize=12)\n",
    "ax.set_title('Audio Waveform with Detected Thunder Events', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "waveform_path = output_dir / 'waveform.png'\n",
    "plt.savefig(waveform_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Waveform saved: {waveform_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7db6bc",
   "metadata": {},
   "source": [
    "## 8. Visualization: Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "\n",
    "# Compute STFT\n",
    "spec_config = config['visualization']['spectrogram']\n",
    "f, t, Zxx = stft(audio_processed, fs=sr, \n",
    "                 nperseg=spec_config['n_fft'], \n",
    "                 noverlap=spec_config['n_fft'] - spec_config['hop_length'])\n",
    "\n",
    "# Convert to dB\n",
    "magnitude = np.abs(Zxx)\n",
    "magnitude_db = 20 * np.log10(magnitude + 1e-10)\n",
    "\n",
    "# Plot spectrogram\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "im = ax.pcolormesh(t, f, magnitude_db, shading='auto', \n",
    "                    cmap=spec_config['colormap'],\n",
    "                    vmin=spec_config['vmin'], vmax=spec_config['vmax'])\n",
    "\n",
    "# Mark events\n",
    "for event in events:\n",
    "    ax.axvline(event['start'], color='red', linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "    ax.axvline(event['end'], color='red', linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Frequency (Hz)', fontsize=12)\n",
    "ax.set_title('Spectrogram with Thunder Events', fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(spec_config['freq_min'], spec_config['freq_max'])\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, label='Magnitude (dB)')\n",
    "plt.tight_layout()\n",
    "\n",
    "spec_path = output_dir / 'spectrogram.png'\n",
    "plt.savefig(spec_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Spectrogram saved: {spec_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfb5e8",
   "metadata": {},
   "source": [
    "## 9. Visualization: Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features to plot\n",
    "plot_features = [\n",
    "    'peak_amplitude', 'rms', 'crest_factor', 'zero_crossing_rate',\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'dominant_frequency',\n",
    "    'kurtosis', 'skewness'\n",
    "]\n",
    "\n",
    "# Filter to existing columns\n",
    "plot_features = [f for f in plot_features if f in features_df.columns]\n",
    "\n",
    "n_features = len(plot_features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, n_rows * 3))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(plot_features):\n",
    "    ax = axes[i]\n",
    "    data = features_df[feature].dropna()\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        ax.hist(data, bins=10, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        ax.set_title(feature, fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Value', fontsize=10)\n",
    "        ax.set_ylabel('Count', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(n_features, len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "hist_path = output_dir / 'feature_distributions.png'\n",
    "plt.savefig(hist_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Feature distributions saved: {hist_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec8b69",
   "metadata": {},
   "source": [
    "## 10. Export Results: CSV, JSON, and Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf74d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save events CSV\n",
    "events_df = pd.DataFrame(events)\n",
    "events_path = output_dir / 'events.csv'\n",
    "events_df.to_csv(events_path, index=False)\n",
    "print(f\"✓ Events saved: {events_path}\")\n",
    "\n",
    "# Save features CSV\n",
    "features_path = output_dir / 'features.csv'\n",
    "features_df.to_csv(features_path, index=False)\n",
    "print(f\"✓ Features saved: {features_path}\")\n",
    "\n",
    "# Save processed audio\n",
    "audio_path = output_dir / 'audio_processed.wav'\n",
    "io.save_audio(audio_path, audio_processed, sr, bit_depth=24, overwrite=True)\n",
    "print(f\"✓ Audio saved: {audio_path}\")\n",
    "\n",
    "# Create and save metadata\n",
    "meta = metadata.create_metadata(\n",
    "    source_url='synthetic_demo',\n",
    "    config=config,\n",
    "    additional_info={\n",
    "        'num_events': len(events),\n",
    "        'audio_duration': len(audio_processed) / sr,\n",
    "        'sample_rate': sr,\n",
    "        'notebook': '00_quickstart.ipynb'\n",
    "    }\n",
    ")\n",
    "\n",
    "meta_path = output_dir / 'meta.json'\n",
    "metadata.save_metadata(meta, meta_path)\n",
    "print(f\"✓ Metadata saved: {meta_path}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All results saved to:\")\n",
    "print(f\"  {output_dir}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0bb11b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete thunder acoustics analysis pipeline:\n",
    "\n",
    "✅ **Preprocessing**: Bandpass filter (20-6000 Hz), noise reduction, normalization  \n",
    "✅ **Event Detection**: Combined energy + spectral flux detection  \n",
    "✅ **Feature Extraction**: 15+ acoustic features (time/frequency/statistical)  \n",
    "✅ **Visualization**: Waveform, spectrogram, feature distributions  \n",
    "✅ **Export**: CSV, JSON, WAV files  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Real Data**: Use `scripts/extract_audio.py` to process actual video files\n",
    "2. **Parameter Tuning**: Try `notebooks/10_event_detection_eval.ipynb` for threshold sensitivity analysis\n",
    "3. **Feature Analysis**: Explore `notebooks/20_features_scouting.ipynb` for correlation and PCA\n",
    "4. **Batch Processing**: Use `Makefile` targets for automated pipelines\n",
    "\n",
    "### CLI Usage\n",
    "\n",
    "```bash\n",
    "# Extract audio from video\n",
    "python scripts/extract_audio.py --video video.mp4 --output audio.wav\n",
    "\n",
    "# Detect events\n",
    "python scripts/detect_events.py --audio audio.wav --output events.csv\n",
    "\n",
    "# Compute features\n",
    "python scripts/compute_features.py --audio audio.wav --events events.csv --output features.csv\n",
    "\n",
    "# Visualize\n",
    "python scripts/visualize.py --audio audio.wav --events events.csv --features features.csv --output-dir outputs/viz/\n",
    "\n",
    "# Generate report\n",
    "python scripts/build_report.py --events events.csv --features features.csv --meta meta.json --viz-dir outputs/viz/ --output report.md\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
